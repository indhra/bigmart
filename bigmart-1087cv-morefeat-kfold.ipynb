{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:17:18.280515Z","iopub.execute_input":"2025-09-07T13:17:18.280832Z","iopub.status.idle":"2025-09-07T13:17:21.635231Z","shell.execute_reply.started":"2025-09-07T13:17:18.280810Z","shell.execute_reply":"2025-09-07T13:17:21.634360Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, StackingRegressor, HistGradientBoostingRegressor\nfrom sklearn.linear_model import RidgeCV, LassoCV\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# --- 1. Data Loading and Preprocessing ---\n\ndef load_data(train_file, test_file):\n    \"\"\"\n    Loads and combines the training and testing datasets for consistent preprocessing.\n    \"\"\"\n    try:\n        train_df = pd.read_csv(train_file)\n        test_df = pd.read_csv(test_file)\n    except FileNotFoundError as e:\n        print(f\"Error: {e}. Please ensure the files exist.\")\n        return None, None\n    \n    train_df['source'] = 'train'\n    test_df['source'] = 'test'\n    combined_df = pd.concat([train_df, test_df], ignore_index=True, sort=False)\n    \n    # Store the original Item_Identifier and Outlet_Identifier for the submission file\n    test_ids = test_df[['Item_Identifier', 'Outlet_Identifier']]\n    return combined_df, test_ids\n\ndef preprocess_features(df):\n    \"\"\"\n    Performs advanced feature engineering, cleaning, and imputation.\n    \"\"\"\n    # Impute missing Item_Weight using the median per Item_Identifier\n    # Using median is more robust to outliers than mean.\n    df['Item_Weight'] = df.groupby('Item_Identifier')['Item_Weight'].transform(\n        lambda x: x.fillna(x.median())\n    )\n    \n    # Impute missing Outlet_Size based on the mode of the Outlet_Type\n    outlet_sizes_mode = df.groupby('Outlet_Type')['Outlet_Size'].apply(lambda x: x.mode().iloc[0])\n    df['Outlet_Size'] = df.apply(\n        lambda row: outlet_sizes_mode[row['Outlet_Type']] if pd.isna(row['Outlet_Size']) else row['Outlet_Size'],\n        axis=1\n    )\n    \n    # Handle categorical feature inconsistencies\n    df['Item_Fat_Content'] = df['Item_Fat_Content'].replace({'low fat':'Low Fat', 'LF':'Low Fat', 'reg':'Regular'})\n    \n    # --- Advanced Feature Engineering ---\n    \n    # 1. New feature for Outlet Age\n    df['Outlet_Years'] = 2013 - df['Outlet_Establishment_Year']\n    \n    # 2. Correcting and creating new visibility features\n    # First, replace 0 visibility with the mean visibility of that item across all outlets\n    visibility_means = df.groupby('Item_Identifier')['Item_Visibility'].transform(\n        lambda x: x.replace(0, x[x != 0].mean())\n    )\n    # If an item had 0 visibility across all its appearances, fill with the global average visibility\n    df['Item_Visibility'] = visibility_means.fillna(df['Item_Visibility'].mean())\n    \n    # Create a new feature: visibility per outlet type\n    df['Item_Visibility_per_Outlet_Type'] = df['Item_Visibility'] / df.groupby('Outlet_Type')['Item_Visibility'].transform('mean')\n\n    # 3. Item_MRP Bins\n    # Binning the Item_MRP into categories can help the model capture non-linear relationships.\n    df['Item_MRP_Bins'] = pd.cut(df['Item_MRP'], bins=[0, 70, 140, 210, 280], labels=['Low', 'Medium', 'High', 'Very_High'])\n    \n    # 4. Item_Type Grouping\n    df['Item_Type_Combined'] = df['Item_Identifier'].apply(lambda x: x[:2])\n    df['Item_Type_Combined'] = df['Item_Type_Combined'].replace({'DR': 'Drinks', 'FD': 'Food', 'NC': 'Non-Consumables'})\n    \n    return df\n\ndef separate_and_encode(df):\n    \"\"\"\n    Separates the combined data and applies a single OneHotEncoder.\n    \"\"\"\n    # Define features to be dropped before encoding\n    drop_cols = ['Item_Identifier', 'Outlet_Establishment_Year']\n    \n    # Separate data back into train and test sets\n    train_processed = df[df['source'] == 'train'].drop('source', axis=1)\n    test_processed = df[df['source'] == 'test'].drop('source', axis=1)\n\n    X_train = train_processed.drop(['Item_Outlet_Sales'] + drop_cols, axis=1)\n    y_train = train_processed['Item_Outlet_Sales']\n    \n    X_test = test_processed.drop(drop_cols, axis=1)\n\n    # Use OneHotEncoder within a ColumnTransformer\n    categorical_cols = [\n        'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size',\n        'Outlet_Location_Type', 'Outlet_Type', 'Item_Type_Combined', 'Item_MRP_Bins'\n    ]\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n        ],\n        remainder='passthrough'\n    )\n\n    X_train_encoded = preprocessor.fit_transform(X_train)\n    X_test_encoded = preprocessor.transform(X_test)\n    \n    return X_train_encoded, y_train, X_test_encoded\n\n# --- 2. Ensemble Model Building and Training ---\n\ndef build_stacked_model():\n    \"\"\"\n    Builds a Stacking Regressor model with a more diverse set of base estimators.\n    \"\"\"\n    # Optimized hyperparameters for the base models to reduce overfitting\n    # Added 'tree_method' for XGBoost and 'device' for LightGBM to enable GPU usage.\n    estimators = [\n        ('xgb', xgb.XGBRegressor(\n            objective='reg:squarederror', n_estimators=100, learning_rate=0.03,\n            max_depth=4, subsample=0.7, colsample_bytree=0.7, reg_alpha=0.005, \n            random_state=42, n_jobs=-1,\n            tree_method='gpu_hist' # Enables GPU for faster training\n        )),\n        ('gbr', GradientBoostingRegressor(\n            n_estimators=1000, learning_rate=0.03, max_depth=3,\n            min_samples_leaf=20, max_features='sqrt', random_state=42\n        )),\n        ('lgbm', lgb.LGBMRegressor(\n            objective='regression', n_estimators=1000, learning_rate=0.03,\n            num_leaves=31, min_child_samples=20, subsample=0.7, \n            colsample_bytree=0.7, reg_alpha=0.001, random_state=42, n_jobs=-1,\n            device='gpu' # Enables GPU for faster training\n        )),\n        ('hgbm', HistGradientBoostingRegressor(\n            max_iter=1000, learning_rate=0.03, max_leaf_nodes=31, \n            min_samples_leaf=20, random_state=42\n        ))\n    ]\n\n    # Use a more flexible meta-regressor like LassoCV\n    # The 'normalize' parameter was removed in recent scikit-learn versions, so it's been removed here.\n    meta_regressor = LassoCV(\n        eps=1e-5, n_alphas=100, random_state=42\n    )\n    \n    # Create the StackingRegressor with 10-fold cross-validation\n    stacked_model = StackingRegressor(\n        estimators=estimators,\n        final_estimator=meta_regressor,\n        cv=5, # Increased folds for more robust cross-validation\n        n_jobs=-1\n    )\n    \n    return stacked_model\n\n# --- 3. Cross-Validation and Prediction ---\n\ndef train_and_predict(model, X_train, y_train, X_test):\n    \"\"\"\n    Trains the model using K-Fold cross-validation and makes predictions.\n    \"\"\"\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    oof_predictions = np.zeros(X_train.shape[0])\n    test_predictions = np.zeros(X_test.shape[0])\n    \n    print(\"Starting K-Fold Cross-Validation...\")\n    for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n        print(f\"--- Fold {fold+1}/{kf.n_splits} ---\")\n        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n        \n        model.fit(X_train_fold, y_train_fold)\n        \n        oof_preds = model.predict(X_val_fold)\n        oof_predictions[val_index] = oof_preds\n        \n        fold_rmse = np.sqrt(mean_squared_error(y_val_fold, oof_preds))\n        print(f\"Fold {fold+1} RMSE: {fold_rmse:.4f}\")\n        \n        test_predictions += model.predict(X_test) / kf.n_splits\n    \n    overall_rmse = np.sqrt(mean_squared_error(y_train, oof_predictions))\n    print(f\"\\nOverall Cross-Validation RMSE: {overall_rmse:.4f}\")\n    \n    return test_predictions\n\n# --- 4. Main Execution Block ---\n\ndef main():\n    \"\"\"\n    Main function to run the entire prediction pipeline.\n    \"\"\"\n    print(\"Loading and preprocessing data...\")\n    combined_df, test_ids = load_data('/kaggle/input/big-mart/train.csv', '/kaggle/input/big-mart/test.csv')\n\n    if combined_df is None:\n        return\n\n    combined_df = preprocess_features(combined_df.copy())\n    \n    X_train_encoded, y_train, X_test_encoded = separate_and_encode(combined_df)\n\n    print(\"Building the advanced ensemble model...\")\n    stacked_model = build_stacked_model()\n    \n    test_predictions = train_and_predict(stacked_model, X_train_encoded, y_train, X_test_encoded)\n    \n    # Create the submission DataFrame\n    submission_df = test_ids.copy()\n    submission_df['Item_Outlet_Sales'] = test_predictions\n    \n    # Post-process predictions to be non-negative\n    submission_df['Item_Outlet_Sales'] = np.maximum(0, submission_df['Item_Outlet_Sales'])\n    \n    submission_df.to_csv('submission.csv', index=False)\n    print(\"\\nPrediction complete. The output file 'submission.csv' has been generated.\")\n    print(\"\\nHead of the submission file:\")\n    print(submission_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:17:21.636683Z","iopub.execute_input":"2025-09-07T13:17:21.636970Z","iopub.status.idle":"2025-09-07T13:22:45.433208Z","shell.execute_reply.started":"2025-09-07T13:17:21.636944Z","shell.execute_reply":"2025-09-07T13:22:45.432417Z"}},"outputs":[{"name":"stdout","text":"Loading and preprocessing data...\nBuilding the advanced ensemble model...\nStarting K-Fold Cross-Validation...\n--- Fold 1/5 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:17:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n[13:17:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n[13:17:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:17:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1095\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1097\n[LightGBM] [Info] Total Bins 1096\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1097\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.009171 secs. 1 sparse feature groups\n[LightGBM] [Info] [LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.013366 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2192.692789\n12 dense feature groups (0.06 MB) transferred to GPU in 0.006373 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2202.712505\n[LightGBM] [Info] Start training from score 2218.316567\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.021628 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2194.279807\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1099\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.001808 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2203.825707\nFold 1 RMSE: 1017.5637\n--- Fold 2/5 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:18:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n[13:18:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1096\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1098\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1097\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1099\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.012763 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Start training from score 2200.952909\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.019829 secs. 1 sparse feature groups\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.014303 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2183.393929\n[LightGBM] [Info] Start training from score 2180.095693\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.015347 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2187.144457\n","output_type":"stream"},{"name":"stderr","text":"[13:18:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:18:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1098\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.004543 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2196.369724\nFold 2 RMSE: 1076.5898\n--- Fold 3/5 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:19:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n[13:19:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n[13:19:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:19:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1101\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1098\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] Total Bins 1099\n[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1099\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n","output_type":"stream"},{"name":"stderr","text":"[13:19:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.017546 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.009406 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2167.556337\n[LightGBM] [Info] Start training from score 2203.346321\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.007050 secs. 1 sparse feature groups\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.012569 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2192.979452\n[LightGBM] [Info] Start training from score 2184.299851\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1101\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.007061 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2182.546471\nFold 3 RMSE: 1068.0974\n--- Fold 4/5 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:20:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n[13:20:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1099\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1097\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1097\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1096\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.017439 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2157.270359[LightGBM] [Info] \n12 dense feature groups (0.06 MB) transferred to GPU in 0.015061 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2177.373370\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.014776 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2161.833072\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.021346 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2169.477384\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1100\n[LightGBM] [Info] Number of data points in the train set: 5456, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.008422 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2175.146636\nFold 4 RMSE: 1113.1811\n--- Fold 5/5 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:21:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:21:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n[13:21:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1098\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] Total Bins 1096\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1099\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1100\n[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.014399 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.011416 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2147.905221\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.015936 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2165.637469\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.008043 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2154.446292\n[LightGBM] [Info] Start training from score 2162.185074\n","output_type":"stream"},{"name":"stderr","text":"[13:21:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n[13:21:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 1099\n[LightGBM] [Info] Number of data points in the train set: 5456, number of used features: 50\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 12 dense feature groups (0.06 MB) transferred to GPU in 0.002810 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2170.457236\nFold 5 RMSE: 1115.4590\n\nOverall Cross-Validation RMSE: 1078.7625\n\nPrediction complete. The output file 'submission.csv' has been generated.\n\nHead of the submission file:\n| Item_Identifier   | Outlet_Identifier   | Item_Outlet_Sales   |\n|:------------------|:--------------------|:--------------------|\n| FDW58             | OUT049              | 1674.41             |\n| FDW14             | OUT017              | 1371.82             |\n| NCN55             | OUT010              | 603.293             |\n| FDQ58             | OUT017              | 2533.7              |\n| FDY38             | OUT027              | 6115.03             |\n","output_type":"stream"}],"execution_count":4}]}